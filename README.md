# SQL Data Cleaning Portfolio

## ðŸ“Œ Overview
This repository is a collection of **SQL scripts** focused exclusively on **data cleaning and preprocessing**. Each file represents a different project or dataset where I apply SQL techniques to improve data quality and prepare it for analysis.  

The main goal of this repository is to **showcase my SQL data cleaning skills**, covering a wide range of scenarios such as handling missing values, standardizing categorical fields, removing duplicates, validating data formats, and more.  

---

## ðŸ”‘ Features
- Cleaning raw datasets using SQL only (no external tools).  
- Standardizing categorical values (e.g., order statuses, complaint types).  
- Handling missing or null values with appropriate strategies.  
- Identifying and removing duplicate records.  
- Normalizing inconsistent text values (case, spacing, formatting).  
- Validating data fields (dates, zip codes, IDs, etc.).  

---

## ðŸ“‚ Repository Structure
- Each `.sql` file corresponds to a **standalone project** or dataset.  
- Files are named descriptively (e.g., `clean_orders.sql`, `nyc311_cleaning.sql`).  
- Scripts are self-contained and documented with comments.  

---

## How to Use
1. Clone this repository:  
   ```bash
   git clone https://github.com/yourusername/sql-data-cleaning.git
   cd sql-data-cleaning
   ```
2. Open any `.sql` file in your SQL environment (PostgreSQL, MySQL, or SQLite).  
3. Run the queries against the dataset to reproduce the cleaning steps.  

---

## ðŸ“ˆ Example Projects
- **Order Data Cleaning** â†’ Standardized order statuses (`Delivered`, `Returned`, etc.).  
- *(More to come â€” this repository will be updated periodically)*  

---

## Goal
This is an **ongoing portfolio project** where I demonstrate practical **data cleaning skills in SQL**. As I complete new projects, Iâ€™ll continue adding scripts that solve real-world data quality problems.  
